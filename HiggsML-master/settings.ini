; Lines beginning with the semicolon ';' like this one 
; are comments and are ignored by the Configuration Parser 

[paths]

; Please update the dataPath to point to the 
; folder where the data is stored in your
; computer.

path_data: 	/local/data/public/vr308/higgs.csv
datafile: 	higgs.csv

[algorithms]

; This section lists the suite of classifiers one can train and test on the higgs dataset 
; using the codebase provided.

; -> Please choose one from the list below and enter selection, the current choice is set to DT. 

; DT for Single Decision Tree Classifier 
; BDT for Boosted Decision Trees Classifier 
; RF for Random forest
; ET for Extremely Randomized Trees Classifier
; BRF for Boosted Random Forests
; BXT for Boosted Extremely Random Trees

algorithm: BXT

[algorithmName]

DT: Decision Tree
BDT: Boosted Decision Trees
RF: Random Forest
ET: Extremely Random Trees
BRF: Boosted Random Forests
BXT: Boosted Extremely Random Trees

[pipeline]

; This section allows the user to change the modes of the learning pipeline.
; impute_missing: Allows user to choose whether to run the algorithm with missing values imputed from the median of the remaining values or just leave them as missing.Tree based classifiers are equipped to deal with missing values by treating all data with any missing features as a separate category.
; hyperparameter_tuning: Allows user to choose whether to conduct parameter tuning as part of the training process (will take longer) or just pick up the defaults listed below. The default choice of parameters are optimized using a grid search rather than just an arbitrary choice.  
; significance_curve: Allows user to specify whether to generate a significance curve graph which would be saved in folder /Graphs/.
; weighted: Allows user to specify whether to weight samples by their importance weights while training or give each sample a uniform weight.

impute_missing: True
hyperparameter_tuning: False
significance_curve: True
weighted: True

[userParams]

; This section prescribes pre-optimized parameters for the 
; higgs training problem, users can twiddle with the parameters 
; below for each specified algorithm and observe the difference in
; saved results in /Results/.

threshold: 85

[DT]

; This model is a single pass binary decision tree

criterion: gini
max_features: 20
max_depth: 10
min_samples_split: 100
min_samples_leaf: 100

[BDT]

; This model is a boosted ensemble of decision trees

n_estimators: 10
learning_rate: 0.7

[RF]

; This model is a bagged ensemble of decision trees 

n_estimators: 100
criterion: gini
max_features: 20
max_depth: 13
min_samples_split: 150
min_samples_leaf: 150

[ET]

; This model is a bagged ensemble of extremely random trees 

n_estimators: 100
criterion: gini
max_features: 20
max_depth: 13
min_samples_split: 150
min_samples_leaf: 150

[BRF]

; This model is a boosted ensemble of Random Forests, the parameters of the base estimator (RF) are read from the respective section.

n_estimators: 20
learning_rate: 0.73

[BXT]

; This model is a boosted ensemble Extremely Random trees, the parameters of the base estimator (ET) are read from the respective section.

n_estimators: 20
learning_rate: 0.73


